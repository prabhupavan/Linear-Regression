# Decision Tree

A decision tree is a type of supervised machine learning used to categorize or make predictions based on how a previous set of questions were answered.Decision trees can be used for classification as well as regression problems. The name itself suggests that it uses a flowchart like a tree structure to show the predictions that result from a series of feature-based splits.
Decision trees imitate human thinking, so it’s generally easy for data scientists to understand and interpret the results. It starts with a root node and ends with a decision made by leaves.

![image](https://user-images.githubusercontent.com/87564129/195990383-9dd7c9c0-86fa-4537-9737-8ab06e8cd633.png)

### Root Nodes : 
It is the node present at the beginning of a decision tree from this node the population starts dividing according to various features.

### Decision Nodes :
The nodes we get after splitting the root nodes are called Decision Node

### Leaf Nodes :
The nodes where further splitting is not possible are called leaf nodes or terminal nodes

### Sub-tree :
Just like a small portion of a graph is called sub-graph similarly a sub-section of this decision tree is called sub-tree.

### Pruning : 
It is nothing but cutting down some nodes to stop overfitting.


![image](https://user-images.githubusercontent.com/87564129/195990509-96c10ac1-f158-432e-875a-2612c7d5f097.png)

A decision tree resembles, well, a tree. The base of the tree is the root node. From the root node flows a series of decision nodes that depict decisions to be made. From the decision nodes are leaf nodes that represent the consequences of those decisions. Each decision node represents a question or split point, and the leaf nodes that stem from a decision node represent the possible answers. Leaf nodes sprout from decision nodes similar to how a leaf sprouts on a tree branch. This is why we call each subsection of a decision tree a “branch.” 
